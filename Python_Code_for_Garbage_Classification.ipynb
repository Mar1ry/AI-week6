{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mar1ry/AI-week6/blob/main/Python_Code_for_Garbage_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "# Define the path to your dataset.\n",
        "# IMPORTANT: Replace 'path/to/your/garbage_dataset' with the actual path\n",
        "# where your image folders (metal, plastic, glass, paper) are located.\n",
        "# Example structure:\n",
        "# garbage_dataset/\n",
        "# ├── metal/\n",
        "# │   ├── image1.jpg\n",
        "# │   └── image2.png\n",
        "# ├── plastic/\n",
        "# │   ├── imageA.jpeg\n",
        "# │   └── imageB.jpg\n",
        "# ├── glass/\n",
        "# │   ├── imageX.gif\n",
        "# │   └── imageY.png\n",
        "# └── paper/\n",
        "#     ├── imageP.jpg\n",
        "#     └── imageQ.jpeg\n",
        "DATA_DIR = 'path/to/your/garbage_dataset' # <<<--- CHANGE THIS PATH\n",
        "\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10 # You might need more epochs for better performance\n",
        "NUM_CLASSES = 4 # metal, plastic, glass, paper\n",
        "\n",
        "# --- 1. Data Loading and Preprocessing ---\n",
        "print(\"--- Setting up Data Generators ---\")\n",
        "\n",
        "# ImageDataGenerator is used for data augmentation and scaling.\n",
        "# rescale=1./255 normalizes pixel values from [0, 255] to [0, 1].\n",
        "# Data augmentation helps prevent overfitting and makes the model more robust.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2, # 20% of data for validation\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Only rescale for the test set, no augmentation.\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load images from directories and apply transformations.\n",
        "# 'subset' argument is used to split data into training and validation sets.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', # Use 'categorical' for multi-class classification\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Get class names (e.g., ['glass', 'metal', 'paper', 'plastic'])\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(f\"Detected classes: {class_names}\")\n",
        "\n",
        "# --- 2. Model Selection (Transfer Learning with MobileNetV2) ---\n",
        "print(\"\\n--- Building the Model with Transfer Learning ---\")\n",
        "\n",
        "# Load the MobileNetV2 model pre-trained on ImageNet.\n",
        "# include_top=False means we don't include the classification head of MobileNetV2,\n",
        "# as we will add our own for our specific number of classes.\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False,\n",
        "                         input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "# Freeze the layers of the base model so they are not updated during training.\n",
        "# This preserves the learned features from ImageNet.\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom classification layers on top of the base model.\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x) # Converts the feature maps to a single vector per image\n",
        "x = Dense(128, activation='relu')(x) # A fully connected layer\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x) # Output layer with softmax for multi-class\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# --- 3. Model Compilation ---\n",
        "print(\"\\n--- Compiling the Model ---\")\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --- 4. Model Training ---\n",
        "print(\"\\n--- Training the Model ---\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "# --- 5. Model Evaluation (on the validation set during training) ---\n",
        "# The evaluation metrics (accuracy, loss) for both training and validation\n",
        "# are available in the 'history' object.\n",
        "print(\"\\n--- Training Complete ---\")\n",
        "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "\n",
        "# You would typically have a separate test set for final, unbiased evaluation.\n",
        "# For simplicity, we've used the validation set during training.\n",
        "# To evaluate on a dedicated test set:\n",
        "# test_generator = test_datagen.flow_from_directory(\n",
        "#     'path/to/your/test_dataset', # <<<--- CHANGE THIS PATH IF YOU HAVE A SEPARATE TEST SET\n",
        "#     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     class_mode='categorical',\n",
        "#     shuffle=False # Important for consistent evaluation\n",
        "# )\n",
        "# print(\"\\n--- Evaluating on Test Set ---\")\n",
        "# loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
        "# print(f\"Test Loss: {loss:.4f}\")\n",
        "# print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# --- Optional: Save the trained model ---\n",
        "# print(\"\\n--- Saving the Model ---\")\n",
        "# model.save('garbage_classifier_model.h5')\n",
        "# print(\"Model saved as 'garbage_classifier_model.h5'\")\n",
        "\n",
        "# --- Optional: Make a prediction on a new image ---\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def predict_image(img_path):\n",
        "#     img = image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "#     img_array = image.img_to_array(img)\n",
        "#     img_array = np.expand_dims(img_array, axis=0) # Create a batch\n",
        "#     img_array /= 255.0 # Rescale the image\n",
        "\n",
        "#     predictions = model.predict(img_array)\n",
        "#     predicted_class_index = np.argmax(predictions[0])\n",
        "#     predicted_class_name = class_names[predicted_class_index]\n",
        "#     confidence = predictions[0][predicted_class_index] * 100\n",
        "\n",
        "#     plt.imshow(img)\n",
        "#     plt.title(f\"Predicted: {predicted_class_name} ({confidence:.2f}%)\")\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "\n",
        "# # Example usage (uncomment and provide a test image path)\n",
        "# # if os.path.exists('path/to/your/test_image.jpg'):\n",
        "# #     predict_image('path/to/your/test_image.jpg') # <<<--- CHANGE THIS PATH\n",
        "# # else:\n",
        "# #     print(\"\\nTest image not found. Please provide a valid path to test prediction.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "1PS0LiiBOK5l"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}